---
title: "Ch5"
output: html_document
---

## 5.2.4 Exercises

Find all flights that:

Had an arrival delay of two or more hours

```{r}
library(nycflights13)
library(tidyverse)

filter(flights, arr_delay >= 120)
```

Flew to Houston (IAH or HOU)

```{r}
filter(flights, dest %in% c("IAH", "HOU"))
```

Were operated by United, American, or Delta

```{r}
filter(flights, carrier %in% c("AA", "DL", "UA"))
```

Departed in summer (July, August, and September)
```{r}
filter(flights, month %in% 7:9)
```

Arrived more than two hours late, but didn’t leave late

```{r}
filter(flights, arr_delay > 120 & dep_delay == 0)
```

Were delayed by at least an hour, but made up over 30 minutes in flight

```{r}
filter(flights, dep_delay >= 60 & (dep_delay - arr_delay >= 30) )
```

Departed between midnight and 6am (inclusive)
```{r}
filter(flights, dep_time >= 2359 & dep_time <= 600)
```

Another useful dplyr filtering helper is between(). What does it do? Can you use it to simplify the code needed to answer the previous challenges?

```{r}
filter(flights, between(dep_time, 2359, 600))
```

How many flights have a missing dep_time? What other variables are missing? What might these rows represent?
```{r}
sum(is.na(flights$dep_time))

map_dbl(flights, ~ sum(is.na(.x)))
```

Why is NA ^ 0 not missing? Why is NA | TRUE not missing? Why is FALSE & NA not missing? Can you figure out the general rule? (NA * 0 is a tricky counterexample!)

Because anything that is `^ 0` equals `1`.
Because NA | TRUE is saying whether one of the two is `TRUE` and the second one is.
Because at least one of the two expressions can be tested: FALSE & NA. In NA & NA neither can be tested and the results is `NA & NA`.

The general rule is that whenever there is a logical expressions, if one can be tested, then the result shouldn't be `NA`. And any operation that the results is determined, regardless of the number, the inputting `NA` does not affect the result.

## 5.3.1 Exercises

How could you use arrange() to sort all missing values to the start? (Hint: use is.na()).
```{r}
df <- tibble(x = c(5, 2, NA))
arrange(df, desc(is.na(x)))
```
We're basically saying, those which are `TRUE` to being `NA`, sort them in descending order.

Sort flights to find the most delayed flights. Find the flights that left earliest.
```{r}
arrange(flights, dep_delay)

arrange(flights, desc(dep_delay))
```

Sort flights to find the fastest flights.

```{r}
arrange(flights, air_time)
```

Which flights travelled the longest? Which travelled the shortest?
```{r}
# Longest
filter(flights, air_time == max(air_time, na.rm = T))

# Shortest
filter(flights, air_time == min(air_time, na.rm = T))
```

## 5.4.1 Exercises

Brainstorm as many ways as possible to select dep_time, dep_delay, arr_time, and arr_delay from flights.

```{r}
select(flights, dep_time, dep_delay, arr_time, arr_delay)
select(flights, starts_with("dep"), starts_with("arr"))
```

What happens if you include the name of a variable multiple times in a select() call?

```{r}
select(flights, dep_time, dep_time)
```

What does the one_of() function do? Why might it be helpful in conjunction with this vector?
```{r}
vars <- c("year", "month", "day", "dep_delay", "arr_delay")
select(flights, one_of(vars))
```

It works because select only accepts variable names without `" "` quotes. By including inside `one_of()` one can use character names.

Does the result of running the following code surprise you? How do the select helpers deal with case by default? How can you change that default?

By default, each select_helper function ignore the cases of the variables.

```{r}
select(flights, contains("TIME"))
```

With this command you can treat each name as literal:
```{r}
select(flights, contains("TIME", ignore.case = F))
```

```{r}
flights_sml <- select(flights, 
  year:day, 
  ends_with("delay"), 
  distance, 
  air_time
)

mutate(flights_sml,
  gain = arr_delay - dep_delay,
  speed = distance / air_time * 60
)

x <- c(5, 1, 3, 2, 2, NA)
row_number(x)
min_rank(x)
dense_rank(x)
percent_rank(x)
cume_dist(x)
```

## 5.5.2 Exercises

Currently dep_time and sched_dep_time are convenient to look at, but hard to compute with because they’re not really continuous numbers. Convert them to a more convenient representation of number of minutes since midnight.

```{r}
View(arrange(flights, dep_time, sched_dep_time))
```

Compare air_time with arr_time - dep_time. What do you expect to see? What do you see? What do you need to do to fix it?

I would expect to see the difference in hours and minutes just as the two first columns. Instead, it's a continuous number of minutes. To fix it, we just have to convert minutes to hours

```{r}
View(select(flights, dep_time, arr_time, air_time))
```

Compare dep_time, sched_dep_time, and dep_delay. How would you expect those three numbers to be related?

Find the 10 most delayed flights using a ranking function. How do you want to handle ties? Carefully read the documentation for min_rank().

What does 1:3 + 1:10 return? Why?

What trigonometric functions does R provide?

### STILL TO DO

## 5.6.7 Exercises

Brainstorm at least 5 different ways to assess the typical delay characteristics of a group of flights. Consider the following scenarios:

A flight is 15 minutes early 50% of the time, and 15 minutes late 50% of the time.

```{r}
# Exchange 15 with -15

flights %>%
  mutate(time = arr_delay == 15) %>%
  group_by(flight) %>%
  summarise(delay = mean(time, na.rm = T)) %>%
  filter(delay == 0.5)

flights %>%
  group_by(flight) %>%
  summarise(delay = mean(arr_delay == 15, na.rm = T)) %>%
  filter(delay == 0.5)

flights %>%
  group_by(flight) %>%
  summarise(delay = sum(arr_delay == 15) / n()) %>%
  filter(delay == 0.5)

flights %>%
  group_by(flight) %>%
  summarise(delay = sum(arr_delay == 15, na.rm = T) / length(arr_delay)) %>%
  filter(delay == 0.5)

flights %>%
  group_by(flight) %>%
  summarise(delay = median(arr_delay == 15, na.rm = T)) %>%
  filter(delay == 0.5)
```

A flight is always 10 minutes late.

```{r}
flights %>%
  group_by(flight) %>%
  summarise(delay = mean(arr_delay == 10, na.rm = T)) %>%
  filter(delay == 1)

flights %>%
  filter(!is.na(arr_delay)) %>%
  group_by(flight) %>%
  summarise(delay = sum(arr_delay == 10) / length(arr_delay)) %>%
  filter(delay == 1)

flights %>%
  group_by(flight) %>%
  summarise(delay = sum(arr_delay == 10, na.rm = T) / length(arr_delay[!is.na(arr_delay)])) %>%
  filter(delay == 1)

flights %>%
  filter(!is.na(arr_delay)) %>%
  group_by(flight) %>%
  mutate(delay = arr_delay == 10) %>%
  summarise(s = sum(delay), n = length(delay)) %>%
  filter(s == n)

flights %>%
  filter(!is.na(arr_delay)) %>%
  group_by(flight) %>%
  summarise(delay = all(arr_delay == 10)) %>%
  filter(delay == T)
```

A flight is 30 minutes early 50% of the time, and 30 minutes late 50% of the time.

```{r}
flights %>%
  group_by(flight) %>%
  summarise(delay = mean(arr_delay == -30, na.rm = T)) %>%
  filter(delay == 0.5)

flights %>%
  filter(!is.na(arr_delay)) %>%
  group_by(flight) %>%
  summarise(delay = sum(arr_delay == -30) / n() ) %>%
  filter(delay == 0.5)

flights %>%
  group_by(flight) %>%
  summarise(delay = sum(arr_delay[!is.na(arr_delay)] == -30) / length(arr_delay[!is.na(arr_delay)]) ) %>%
  filter(delay == 0.5)

flights %>%
  filter(!is.na(arr_delay)) %>%
  mutate(delay = ifelse(arr_delay == -30, 1, 0)) %>%
  select(flight, delay) %>%
  group_by(flight) %>%
  summarise(m = mean(delay, na.rm = T)) %>%
  filter(m == 0.5)

flights %>%
  filter(!is.na(arr_delay)) %>%
  group_by(flight) %>%
  mutate(delay = mean(arr_delay == -30, na.rm = T)) %>%
  select(flight, delay) %>%
  filter(duplicated(flight), delay == 0.5)
```

99% of the time a flight is on time. 1% of the time it’s 2 hours late.

```{r}

flights %>%
  filter(!is.na(arr_delay)) %>%
  group_by(flight) %>%
  summarise(arr = mean(arr_delay == 90)) %>%
  filter(arr == 0.01)


```

Which is more important: arrival delay or departure delay?

Arrival delay

Come up with another approach that will give you the same output as:
```{r}
not_cancelled <- flights %>% 
  filter(!is.na(dep_delay), !is.na(arr_delay))

not_cancelled %>%
  count(dest)

# and

not_cancelled %>%
  count(tailnum, wt = distance)
# (without using count()).

#######################

not_cancelled %>%
  group_by(dest) %>%
  summarise(n = n())

# and

not_cancelled %>%
  group_by(tailnum) %>%
  tally(wt = distance)
```

Our definition of cancelled flights `(is.na(dep_delay) | is.na(arr_delay) )` is slightly suboptimal. Why? Which is the most important column?

Because if a flight didn't leave then it was cancelled. If the condition `is.na(dep_delay)` is met, then the flight was cancelled.

Look at the number of cancelled flights per day. Is there a pattern? Is the proportion of cancelled flights related to the average delay?

```{r}
flights %>%
  group_by(day) %>%
  summarise(m = mean(is.na(dep_delay)), m2 = mean(dep_delay, na.rm = T)) %>%
  ggplot(aes(m2, m)) + geom_point() + labs(x = "Avg delay per day", y = "Cancelled flights p day")
```

It looks like there is a positive relationship. The higher the average delay of the day, the higher the proportion of cancelled flights per day.

Which carrier has the worst delays?

```{r}
flights %>%
  group_by(carrier) %>%
  summarise(dep_max = max(dep_delay, na.rm = T),
            arr_max = max(arr_delay, na.rm = T)) %>%
  arrange(desc(dep_max, arr_max)) %>%
  filter(1:n() == 1)
```

Challenge: can you disentangle the effects of bad airports vs. bad carriers? Why/why not? (Hint: think about flights %>% group_by(carrier, dest) %>% summarise(n()))

It might be possible. For example, if we took the average departure delay for each carrier and then computed the deviations over the overall carrier mean from each airport mean, perhaps we can find something out. If the overall mean is, let's say, 25 mins, and then each deviation is ± 1 or 2, then it could be that the airline is bad or that every single bad. I know, it might be more likely that the airline is bad, but we can't be 100% sure. On the other hand, if the overall carrier mean is high and the deviations are all lower except for 1 or 2 airports then the effect is probably the airport effect.

```{r}
flights %>%
  group_by(carrier) %>%
  mutate(avg_carrier = mean(dep_delay, na.rm = T)) %>%
  group_by(carrier, origin) %>%
  mutate(origin_mean = mean(dep_delay, na.rm = T),
         deviations = origin_mean - avg_carrier) %>%
  summarise(deviations = mean(deviations), mean = mean(avg_carrier)) %>%
  ggplot(aes(origin, deviations)) + geom_col() + facet_wrap(~ carrier)

```

Tearing out the effect is not straight forward but we can make some informed guesses. For example, whenever there are substantial deviations, they seem to be higher in EWR airport rather than in other airports. On the other hand, there are some aielines that look particular bad like 9E and MQ. And the same pattern is not found on the vast majority of other airlines, which would suggest it's an airport issues rather than an airline issue.


```{r}
flights %>%
  group_by(carrier, dest) %>%
  summarise(mean_departure = mean(dep_delay, na.rm = T),
            mean_arrival = mean(arr_delay, na.rm = T)) %>%
  View(.)
```

For each plane, count the number of flights before the first delay of greater than 1 hour.

```{r}

flights %>%
  group_by(tailnum, del = dep_delay > 60) %>%
  mutate(min_date = min(time_hour)) %>%
  filter(time_hour > min_date) %>%
  ungroup() %>%
  count(tailnum)

```

What does the sort argument to count() do. When might you use it?

When you want to sort the cases based on the count.
```{r}
flights %>%
  count(flight, sort = T)
```